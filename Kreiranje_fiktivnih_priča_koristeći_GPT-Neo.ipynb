{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f839486c-6d7f-4fb6-8e42-32510b5e519c",
   "metadata": {},
   "source": [
    "# Kreiranje fiktivnih priča koristeći GPT-Neo (Making a fiction story generator using a GPT-Neo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1cb59-d38f-4a13-a529-1ff01c4b2b5e",
   "metadata": {},
   "source": [
    "## 1. Uvod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031523f-1c0b-4229-90f4-6e0ed06b8e24",
   "metadata": {},
   "source": [
    "GPT-Neo je serija jezičnih modela baziranih na transformatorima razvijenih od strane EleutherAI. Oni su trenirani na velikim količinama podataka kako bi naučili obrasce i strukture prirodnog jezika. Naziv \"GPT\" označava \"Generative Pre-trained Transformer,\" što se odnosi na osnovnu arhitekturu, dok \"Neo\" označava novu ili unaprijeđenu verziju ovih modela. Kao i drugi GPT modeli, GPT-Neo je istreniran na ogromnoj količini tekstualnih podataka sa interneta, što mu omogućava da nauči obrasce i strukture prirodnog jezika. Ovo treniranje omogućava GPT-Neu da izvršava širok spektar zadataka vezanih za razumijevanje i generiranje prirodnog jezika, kao što su dopunjavanje teksta, prijevod, odgovaranje na pitanja i mnoge druge, sa impresivnom preciznošću i točnošću. Različite verzije GPT-Nea se mogu razlikovati po veličini modela, podacima za treniranje i fino podešavanje za specifične zadatke. \n",
    "\n",
    "Ja sam koristio GPT-Neo 125M zato što je to model EleutherAI-a sa najmanje parametara, i mogu ga stabilno pokretati na Paperspace platformi. Također, GPT-Neo je opširniji i bolje se ponaša u određenim slučajevima od GPT-3, koji ni nije open-source. Za fino podešavanje, koristio sam sljedeći [skup podataka](https://github.com/facebookresearch/fairseq/tree/main/examples/stories). Ovaj skup podataka sadrži 300.000 priča i promptova za te priče.Tim iz Facebook-a je sakupio priče i promptove sa Reddit-ovog [ WritingPrompts forum](https://www.reddit.com/r/WritingPrompts/), koje su korisnici pisali tokom 3 godine, i kombinirao ih u ovaj skup podataka. WritingPrompts je Reddit zajednica gdje korisnici inspiriraju jedni druge da pišu tako što postavljaju promptove ili upite, a drugi korisnici slobodno odgovaraju u obliku priča. Svaki upit može imati više priča. Promptovi pokrivaju širok spektar tema, dužina i detalja. Priče moraju sadržavati najmanje 30 riječi, izbjegavati vulgarnost i neprikladan sadržaj, i trebaju biti inspirirane odgovarajućim promptom. Kombinirao sam promptove sa odgovarajućim pričama i fino podesio GPT-Neo model koristeći Hugging Face Transformers biblioteku. \n",
    "\n",
    "U ovom notebook-u, koristio sam Hugging Face Trainer API za fino podešavanje mog modela i Paperspace Pro plan za svoje okruženje. Kao metriku sam koristio perpleksnost kako bih provjerio da li je fino podešavanje poboljšalo moj model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a837797a-17b4-4722-9ddd-7b7d755c7856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T17:44:01.465610Z",
     "iopub.status.busy": "2023-08-31T17:44:01.464786Z",
     "iopub.status.idle": "2023-08-31T17:44:02.889977Z",
     "shell.execute_reply": "2023-08-31T17:44:02.889370Z",
     "shell.execute_reply.started": "2023-08-31T17:44:01.465580Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78570c-e859-4bfb-9dbb-94d603583d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff7c3d1-239c-4aca-ba74-231d5aa56c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T11:33:10.779009Z",
     "iopub.status.busy": "2023-09-01T11:33:10.778769Z",
     "iopub.status.idle": "2023-09-01T11:33:18.136150Z",
     "shell.execute_reply": "2023-09-01T11:33:18.135569Z",
     "shell.execute_reply.started": "2023-09-01T11:33:10.778991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.28.0\n",
      "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (1.23.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (0.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.28.0) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.28.0) (2.8)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "Successfully installed transformers-4.28.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f660e963-97c5-4095-9592-4b6f06f2c26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:32:20.703090Z",
     "iopub.status.busy": "2023-08-04T13:32:20.702780Z",
     "iopub.status.idle": "2023-08-04T13:32:23.490492Z",
     "shell.execute_reply": "2023-08-04T13:32:23.489562Z",
     "shell.execute_reply.started": "2023-08-04T13:32:20.703059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.12.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.23.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (18.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5060ce7-c160-40f2-a34e-65f34551ebd0",
   "metadata": {},
   "source": [
    "## 2. Priprema podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d1906-4c24-47f1-944f-ec2e29f60419",
   "metadata": {},
   "source": [
    "### 2.1 Preuzimanje skupa podataka i kombiniranje promptova sa pričama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb5b51-1443-4d07-8750-6feb890eecef",
   "metadata": {},
   "source": [
    "Nakon preuzimanja tekstualnih datoteka s ovog [linka](https://github.com/facebookresearch/fairseq/tree/main/examples/stories). Promptovi i priče su spremljeni u odvojene datoteke. Datoteka valid.wp_source sadrži navedene promptove, dok valid.wp_target sadrži odgovarajuće priče. Također, treba napomenuti da je skup podataka za obuku prilično velik.\n",
    "\n",
    "Kako bih istovremeno unio i prompt i priču u GPT-Neo, spajam propmtove i priče u jednu zajedničku cjelinu. Kao rezultat toga, svaka linija unutar ove ujedinjene datoteke sadrži i prompt i odgovarajuću priču."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2102bf1b-cf89-4ccb-b0ac-45378fa729c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:44:52.719742Z",
     "iopub.status.busy": "2023-07-16T22:44:52.719299Z",
     "iopub.status.idle": "2023-07-16T22:45:02.301724Z",
     "shell.execute_reply": "2023-07-16T22:45:02.300904Z",
     "shell.execute_reply.started": "2023-07-16T22:44:52.719716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: examples/stories: No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0writingPrompts/\n",
      "writingPrompts/test.wp_source\n",
      "writingPrompts/test.wp_target\n",
      "  4  363M    4 15.9M    0     0  29.7M      0  0:00:12 --:--:--  0:00:12 29.6MwritingPrompts/README\n",
      "writingPrompts/valid.wp_source\n",
      "writingPrompts/valid.wp_target\n",
      "writingPrompts/train.wp_target\n",
      " 92  363M   92  336M    0     0  44.7M      0  0:00:08  0:00:07  0:00:01 47.0MwritingPrompts/train.wp_source\n",
      "100  363M  100  363M    0     0  44.9M      0  0:00:08  0:00:08 --:--:-- 47.1M\n"
     ]
    }
   ],
   "source": [
    "!cd examples/stories\n",
    "!curl https://dl.fbaipublicfiles.com/fairseq/data/writingPrompts.tar.gz | tar xvzf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12c8636-b7af-4337-8727-22f3ce4bac53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:40:37.664947Z",
     "iopub.status.busy": "2023-08-29T13:40:37.663867Z",
     "iopub.status.idle": "2023-08-29T13:40:37.669685Z",
     "shell.execute_reply": "2023-08-29T13:40:37.669099Z",
     "shell.execute_reply.started": "2023-08-29T13:40:37.664915Z"
    }
   },
   "outputs": [],
   "source": [
    "DATAPATH='writingPrompts'\n",
    "def combinetext(prompt, story):\n",
    "    fp=open(os.path.join(DATAPATH,prompt),encoding='utf8')\n",
    "    fs=open(os.path.join(DATAPATH,story),encoding='utf8')\n",
    "    prompts=fp.readlines()\n",
    "    stories=fs.readlines()\n",
    "    assert len(prompts)==len(stories)\n",
    "    combine=[]\n",
    "    for i in range(len(prompts)):\n",
    "        combine.append(prompts[i].rstrip()+' <sep> '+\" \".join(stories[i].split()[:300]))\n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da6fa2d-bc0e-4b76-89a5-d5577aa8b0a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:40:40.446496Z",
     "iopub.status.busy": "2023-08-29T13:40:40.445491Z",
     "iopub.status.idle": "2023-08-29T13:40:40.452116Z",
     "shell.execute_reply": "2023-08-29T13:40:40.451404Z",
     "shell.execute_reply.started": "2023-08-29T13:40:40.446466Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleanpunctuation(s):\n",
    "    for p in '!,.:;?':\n",
    "        s=s.replace(' '+p,p)\n",
    "    s=s.replace(' '+'n\\'t','n\\'t')\n",
    "    s=s.replace(' '+'\\'s','\\'s')\n",
    "    s=s.replace(' '+'\\'re','\\'re')\n",
    "    s=s.replace(' '+'\\'ve','\\'ve')\n",
    "    s=s.replace(' '+'\\'ll','\\'ll')\n",
    "    s=s.replace(' '+'\\'am','\\'am')\n",
    "    s=s.replace(' '+'\\'m','\\'m')\n",
    "    s=s.replace(' '+'\\' m','\\'m')\n",
    "    s=s.replace(' '+'\\'m','\\'m')\n",
    "    s=s.replace(' '+'\\' ve','\\'ve')\n",
    "    s=s.replace(' '+'\\' s','\\'s')\n",
    "    s=s.replace('<newline>','\\n')\n",
    "    return s   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1e9f27-8504-4fa0-9ebe-935e5aa286a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:40:46.179441Z",
     "iopub.status.busy": "2023-08-29T13:40:46.178185Z",
     "iopub.status.idle": "2023-08-29T13:41:12.770829Z",
     "shell.execute_reply": "2023-08-29T13:41:12.770200Z",
     "shell.execute_reply.started": "2023-08-29T13:40:46.179395Z"
    }
   },
   "outputs": [],
   "source": [
    "train_text=combinetext('train.wp_source', 'train.wp_target')\n",
    "train_text=list(map(cleanpunctuation,train_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df593041-856d-46ef-afc7-0b982a378411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:41:25.213058Z",
     "iopub.status.busy": "2023-08-29T13:41:25.212393Z",
     "iopub.status.idle": "2023-08-29T13:41:26.771405Z",
     "shell.execute_reply": "2023-08-29T13:41:26.770739Z",
     "shell.execute_reply.started": "2023-08-29T13:41:25.213029Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_text=combinetext('valid.wp_source', 'valid.wp_target')\n",
    "valid_text=list(map(cleanpunctuation,valid_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53ff08f-4e61-4512-ad05-cd75f410c9b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:41:32.259465Z",
     "iopub.status.busy": "2023-08-29T13:41:32.258493Z",
     "iopub.status.idle": "2023-08-29T13:41:33.536450Z",
     "shell.execute_reply": "2023-08-29T13:41:33.535810Z",
     "shell.execute_reply.started": "2023-08-29T13:41:32.259427Z"
    }
   },
   "outputs": [],
   "source": [
    "test_text=combinetext('test.wp_source', 'test.wp_target')\n",
    "test_text=list(map(cleanpunctuation,valid_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ae898-895d-4065-b2fa-f2ee2a6fc985",
   "metadata": {},
   "source": [
    "Primjer kombinirane priče i prompta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f2642e-63a6-4387-a7aa-75cf4a19e17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:41:37.798707Z",
     "iopub.status.busy": "2023-08-29T13:41:37.797859Z",
     "iopub.status.idle": "2023-08-29T13:41:37.802919Z",
     "shell.execute_reply": "2023-08-29T13:41:37.802396Z",
     "shell.execute_reply.started": "2023-08-29T13:41:37.798677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ WP ] Season 30 of Game of Thrones <sep> Note: I just watched Episode 1 of Season 4 and haven't read any of the books, so I don't know what happens after that. Please no spoilers! This is also my first WP post, but constructive feedback is welcome. Also, just for fun I tried to do an unofficial screenplay format, hence the weird capitalization. \\n \\n -- - \\n \\n Fade in to a mound of swords, tips facing us. We hear footsteps on stone, slowly getting closer. Meanwhile, the camera zooms out until we recognize this as The Iron Throne. Camera sweeps around the throne, until we are in front of middle-aged DAENARYS sitting on the throne, face blank. \\n \\n After several seconds, in addition to the footsteps we now also hear the jangle of a maester's chain. Both sounds then stop, and we hear an aged but familiar voice, `` Your Grace... '' \\n \\n The camera turns to face SAM, in full maester garb. We see him approaching the camera for a few seconds, and then switches to a side view as he stops at the base of the stairs. DAENARYS nods and SAM climbs the first set of stairs towards the throne and stops. \\n \\n Looking from behind SAM we see DAENARYS in the throne which towers above her head. To her right stands SIR JORAH, after all these years, he's still protectively looking over her. The Hand of the King's medallion hangs from his armor. \\n \\n SAM: I've just received word from The Wall. It's still holding, but\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b8fe9-5e2a-4bf5-b435-9b5947ab26cd",
   "metadata": {},
   "source": [
    "## 3. Tokenizacija i priprema podataka za Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505fc8c-7595-4176-ad60-53f4bcfd786d",
   "metadata": {},
   "source": [
    "GPT-Neo koristi isti tokenizer kao i GPT-2, Byte-Pair Encoding (BPE) za tokenizaciju niza teksta. BPE počinje s vokabularom pojedinačnih znakova i iterativno spaja najčešće parove znakova u nove podtokene, efikasno kodirajući strukturu teksta.\n",
    "\n",
    "Kako bih osigurao da se nizovi u istoj seriji podataka imaju istu dužinu, postavljam maksimalnu dužinu niza na 512, skraćujem duže nizove i nadopunjavam kraće nizove. Pošto funkcija tokenizer vraća samo input_ids i attention_mask, za potrebe obuke moram pružiti oznake (ciljeve) modelu. Zato stvaram niz oznaka za svaki niz input_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5d257f-d176-4433-8ab2-ca285ea4308f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T11:33:18.712036Z",
     "iopub.status.busy": "2023-09-01T11:33:18.711776Z",
     "iopub.status.idle": "2023-09-01T11:33:21.972219Z",
     "shell.execute_reply": "2023-09-01T11:33:21.971560Z",
     "shell.execute_reply.started": "2023-09-01T11:33:18.712010Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding,GPTNeoForCausalLM, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0032889-c968-4084-b5c9-4c32ace62324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T11:33:21.973610Z",
     "iopub.status.busy": "2023-09-01T11:33:21.973267Z",
     "iopub.status.idle": "2023-09-01T11:33:35.841345Z",
     "shell.execute_reply": "2023-09-01T11:33:35.840677Z",
     "shell.execute_reply.started": "2023-09-01T11:33:21.973592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fae54019d324a69b4c4fdaadcf70c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78d9d6ec8084478a4fa5d62c98de3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed9d2e0ff604ceeb395359da8ae4661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fae9c6ed85f4b1b98dfa7000d76ca84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b098ba38eecf4073a2a0160b20aa0f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a35e0e04b64c04a2ce107d01072e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/470 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da63beab4ed4a12bc88d9547b75556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"Tincando/fiction_story_generator\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"Tincando/fiction_story_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3cbcd3-5ca5-4a01-8151-f5cc89ccb381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:36:27.374666Z",
     "iopub.status.busy": "2023-08-04T13:36:27.374491Z",
     "iopub.status.idle": "2023-08-04T13:42:05.405395Z",
     "shell.execute_reply": "2023-08-04T13:42:05.404755Z",
     "shell.execute_reply.started": "2023-08-04T13:36:27.374650Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "\n",
    "inputs_train = tokenizer(train_text, padding=True,truncation=True,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7d89890-b734-4181-a412-ea974e72b741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:42:54.107529Z",
     "iopub.status.busy": "2023-08-04T13:42:54.106793Z",
     "iopub.status.idle": "2023-08-04T13:43:12.765162Z",
     "shell.execute_reply": "2023-08-04T13:43:12.764394Z",
     "shell.execute_reply.started": "2023-08-04T13:42:54.107503Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_valid=tokenizer(valid_text, padding=True,truncation=True,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f75c74-274e-419b-bc65-3b0088da6487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:15.641002Z",
     "iopub.status.busy": "2023-08-04T13:43:15.640350Z",
     "iopub.status.idle": "2023-08-04T13:43:15.644773Z",
     "shell.execute_reply": "2023-08-04T13:43:15.644221Z",
     "shell.execute_reply.started": "2023-08-04T13:43:15.640974Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_labels(inputs):\n",
    "    labels=[]\n",
    "    for ids,attention_mask in zip(inputs['input_ids'],inputs['attention_mask']):\n",
    "        label=ids.copy()\n",
    "        real_len=sum(attention_mask)\n",
    "        padding_len=len(attention_mask)-sum(attention_mask)\n",
    "        label[:]=label[:real_len]+[-100]*padding_len\n",
    "        labels.append(label)\n",
    "    inputs['labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14274e6-ae90-4ba9-be95-44f0b3042679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:18.602164Z",
     "iopub.status.busy": "2023-08-04T13:43:18.601383Z",
     "iopub.status.idle": "2023-08-04T13:43:25.260444Z",
     "shell.execute_reply": "2023-08-04T13:43:25.259926Z",
     "shell.execute_reply.started": "2023-08-04T13:43:18.602137Z"
    }
   },
   "outputs": [],
   "source": [
    "create_labels(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6768fa8-92b4-4073-9b1a-a49f431e008d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:26.030132Z",
     "iopub.status.busy": "2023-08-04T13:43:26.029649Z",
     "iopub.status.idle": "2023-08-04T13:43:26.258082Z",
     "shell.execute_reply": "2023-08-04T13:43:26.257538Z",
     "shell.execute_reply.started": "2023-08-04T13:43:26.030110Z"
    }
   },
   "outputs": [],
   "source": [
    "create_labels(inputs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066a7978-b958-4f40-ae99-bdb7075130dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:29.159975Z",
     "iopub.status.busy": "2023-08-04T13:43:29.159232Z",
     "iopub.status.idle": "2023-08-04T13:43:29.165845Z",
     "shell.execute_reply": "2023-08-04T13:43:29.165277Z",
     "shell.execute_reply.started": "2023-08-04T13:43:29.159954Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04eafad-c37a-4a0a-ab03-079b6c9ff877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:32.649168Z",
     "iopub.status.busy": "2023-08-04T13:43:32.648559Z",
     "iopub.status.idle": "2023-08-04T13:43:32.651422Z",
     "shell.execute_reply": "2023-08-04T13:43:32.651003Z",
     "shell.execute_reply.started": "2023-08-04T13:43:32.649145Z"
    }
   },
   "outputs": [],
   "source": [
    "traindata=Dataset(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687f6951-122f-4204-b9b5-aa7533182378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:35.439444Z",
     "iopub.status.busy": "2023-08-04T13:43:35.438711Z",
     "iopub.status.idle": "2023-08-04T13:43:35.441751Z",
     "shell.execute_reply": "2023-08-04T13:43:35.441358Z",
     "shell.execute_reply.started": "2023-08-04T13:43:35.439423Z"
    }
   },
   "outputs": [],
   "source": [
    "validdata=Dataset(inputs_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bd814-b905-4bfc-b6bb-e4dea51537f3",
   "metadata": {},
   "source": [
    "## 4. Fino podešavanje modela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c29408-68b4-46d6-8298-0ff2d786c8c7",
   "metadata": {},
   "source": [
    "Broj uzoraka za obuku je 170 375. S jednom GPU na Paperspace-u za obuku modela, trebalo mi je nekoliko dana da potpuno obučim model zbog automatskog gašenja Paperspace-a nakon 6 sati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcf305a-fccb-430a-8a0f-3c2c9b722cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:43:40.158151Z",
     "iopub.status.busy": "2023-08-04T13:43:40.157556Z",
     "iopub.status.idle": "2023-08-04T13:43:40.160601Z",
     "shell.execute_reply": "2023-08-04T13:43:40.160203Z",
     "shell.execute_reply.started": "2023-08-04T13:43:40.158126Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4c2b2cc-e7ea-41d4-b331-9ddd8ccde791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:34:44.749063Z",
     "iopub.status.busy": "2023-07-26T11:34:44.748632Z",
     "iopub.status.idle": "2023-07-26T11:34:44.831049Z",
     "shell.execute_reply": "2023-07-26T11:34:44.830265Z",
     "shell.execute_reply.started": "2023-07-26T11:34:44.749040Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"fiction_story_generator\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    push_to_hub=True,\n",
    "    resume_from_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0aacf7e-ff08-486e-821e-38acf1a343b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:36:00.918837Z",
     "iopub.status.busy": "2023-07-26T11:36:00.918561Z",
     "iopub.status.idle": "2023-07-26T11:36:11.016959Z",
     "shell.execute_reply": "2023-07-26T11:36:11.016136Z",
     "shell.execute_reply.started": "2023-07-26T11:36:00.918816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/fiction_story_generator is already a clone of https://huggingface.co/Tincando/fiction_story_generator. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=traindata,\n",
    "    eval_dataset=validdata,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce38ba76-1ae5-457a-af18-b33c5221ac5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T11:36:14.649460Z",
     "iopub.status.busy": "2023-07-26T11:36:14.648615Z",
     "iopub.status.idle": "2023-07-26T14:02:40.192882Z",
     "shell.execute_reply": "2023-07-26T14:02:40.192203Z",
     "shell.execute_reply.started": "2023-07-26T11:36:14.649390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d51b5677d4241c0a5e80ad798a5c629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20230726_113627-343asbwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tinfants123/huggingface/runs/343asbwk\" target=\"_blank\">devout-flower-15</a></strong> to <a href=\"https://wandb.ai/tinfants123/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170375' max='170375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170375/170375 2:25:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.851700</td>\n",
       "      <td>3.135746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=170375, training_loss=0.10689012991218819, metrics={'train_runtime': 8779.3565, 'train_samples_per_second': 155.251, 'train_steps_per_second': 19.406, 'total_flos': 3.56025273679872e+17, 'train_loss': 0.10689012991218819, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "691774c8-7e37-444b-87b8-2f8a173f9209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T14:25:20.597777Z",
     "iopub.status.busy": "2023-07-26T14:25:20.597208Z",
     "iopub.status.idle": "2023-07-26T14:37:26.576781Z",
     "shell.execute_reply": "2023-07-26T14:37:26.576193Z",
     "shell.execute_reply.started": "2023-07-26T14:25:20.597745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5ace1e490349448478b1ace79cd178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d1b6d2af994e45b386101a703c676f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Jul26_11-34-44_nz4ahzqyb6/events.out.tfevents.1690371380.nz4ahzqyb6.32.0:   0%|          | 1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tincando/fiction_story_generator\n",
      "   be2ee5e..dd2df5c  main -> main\n",
      "\n",
      "To https://huggingface.co/Tincando/fiction_story_generator\n",
      "   dd2df5c..4a5ccd1  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Tincando/fiction_story_generator/commit/dd2df5cce2b1ad5d83b7f80c26273e53890132ff'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f7d13-670e-475b-a238-1c3ead998981",
   "metadata": {},
   "source": [
    "### 4.1. Evaluacija prije finog podešavanja modela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11f219-1140-4cd1-a887-5f31d6ffed7d",
   "metadata": {},
   "source": [
    "Pomoću Hugging Face Transformers paketa, možemo lako preuzeti istrenirani GPT-neo model.\n",
    "\n",
    "Prosječna perpleksnost za validacijski skup podataka prije finog podešavanja iznosi 37.28. Pogledat ćemo perpleksnost i nakon finog podešavanja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccddb672-b91d-41ad-8a0b-c9191239863a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:45:47.283413Z",
     "iopub.status.busy": "2023-08-29T13:45:47.282725Z",
     "iopub.status.idle": "2023-08-29T13:46:00.006451Z",
     "shell.execute_reply": "2023-08-29T13:46:00.005633Z",
     "shell.execute_reply.started": "2023-08-29T13:45:47.283384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12195b1d9ab140efb899bce359b0c2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de5dcedef9748bbb8ff23830e0ce06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76c9cd43-ead6-4405-abbb-ec1229fea858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:47:47.500504Z",
     "iopub.status.busy": "2023-08-04T13:47:47.500230Z",
     "iopub.status.idle": "2023-08-04T13:47:51.886588Z",
     "shell.execute_reply": "2023-08-04T13:47:51.885813Z",
     "shell.execute_reply.started": "2023-08-04T13:47:47.500482Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model1,\n",
    "    train_dataset=traindata,\n",
    "    eval_dataset=validdata,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39064556-c47f-4641-b854-cd676d6f3ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:50:16.557425Z",
     "iopub.status.busy": "2023-08-04T13:50:16.556847Z",
     "iopub.status.idle": "2023-08-04T13:57:19.340299Z",
     "shell.execute_reply": "2023-08-04T13:57:19.339547Z",
     "shell.execute_reply.started": "2023-08-04T13:50:16.557398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 06:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20230804_135718-3je7ytad</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tinfants123/huggingface/runs/3je7ytad\" target=\"_blank\">polar-cherry-16</a></strong> to <a href=\"https://wandb.ai/tinfants123/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40558a7e-b0c6-47c6-8bea-a8b1e152f8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T13:58:40.159305Z",
     "iopub.status.busy": "2023-08-04T13:58:40.158533Z",
     "iopub.status.idle": "2023-08-04T13:58:40.165350Z",
     "shell.execute_reply": "2023-08-04T13:58:40.164007Z",
     "shell.execute_reply.started": "2023-08-04T13:58:40.159278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average perplexity for valid dataset before fine-tuning is:  37.28\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average perplexity for valid dataset before fine-tuning is:  {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1c3e4-d48d-4d79-ba7a-5fe9e3949e38",
   "metadata": {},
   "source": [
    "## 5. Generirajmo priče"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6e9c2-8494-4bf8-ae00-4c2a71fbca56",
   "metadata": {},
   "source": [
    "Izaberemo prompt iz validacijskog skupa podataka, unesemo ga u model i tražimo model da generira priču koja se proteže na 300 riječi. Rezultat su priče koje pokazuju dobru kvalitetu koristeći ugrađenu generate metodu modela, koja nudi različite opcije dekodiranja kao što su greedy decoding, beam-search decoding i nekoliko tehnika uzorkovanja, uključujući uzorkovanje na osnovu temperature i top-k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e679f6-be9a-414a-b2b0-62ce1eee1c51",
   "metadata": {},
   "source": [
    "Objašnjenja za korištene parametre su sljedeća:\n",
    "\n",
    "1. **do_sample**: Kada je postavljeno na False, model koristi greedy decoding.\n",
    "2. **temperature**: Ovo se odnosi na vrijednost koja prilagođava ili utječe na vjerojatnost sljedećeg tokena u sekvenci.\n",
    "3. **top_k**: Određuje koliko vokabularnih tokena sa najvećim vjerojatnoćama će biti zadržano kroz proces filtriranja poznat kao top-k filtriranje.\n",
    "4. **top_p**: Ako je postavljeno na float < 1, samo će se najmanja grupa najvjerojatnijih tokena, čije se pojedinačne vjerojatnoće zajedno iznose na vrijednost veću ili jednaku 'top_p', zadržati za generiranje teksta. To nam omogućava da filtriramo i zadržimo podskup tokena na osnovu njihovih vjerojatnoća kako bismo kontrolirali proces generiranja.\n",
    "5. **repetition_penalty**:Kada je postavljeno na 1.0, to znači da nema kazne za ponavljanje riječi ili tokena u generiranom tekstu. Međutim, ako postavimo vrijednost različitu od 1.0, uvest će se kazna za ponavljajuće riječi, sprječavajući model od generiranja teksta sa previše ponavljanja.\n",
    "6. **num_return_sequences**: Kontrolira koliko različitih izlaznih sekvenci će model proizvesti za svaki unos u seriji podataka. Ako je postavljeno na 1 , dobijemo jednu sekvencu po unosu; ako je postavljeno na veću vrijednost, dobijemo više sekvenci po unosu, svaka predstavlja različit potencijalni nastavak ili odgovor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd01dee0-c672-4dee-96a8-fde15617eae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:52:21.193505Z",
     "iopub.status.busy": "2023-08-29T13:52:21.192972Z",
     "iopub.status.idle": "2023-08-29T13:53:13.369136Z",
     "shell.execute_reply": "2023-08-29T13:53:13.368175Z",
     "shell.execute_reply.started": "2023-08-29T13:52:21.193473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====PROMPT====\n",
      "\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      "\n",
      "====CORRESPONDING STORY===\n",
      "\n",
      " The funeral was the saddest day of my life. I watched as Cameron's mother and father wept over a closed casket. No parent should ever have to bury their child. That is an agony I wouldn't wish on my worst enemy. They tried their best to avoid giving me terrible looks between the tears, but who could blame them? I had just killed their son. \n",
      " \n",
      " Days in the summer had become pretty routine. Wake up, eat breakfast, long run, jump in the pool, and then the fun part, go with a few friends to the sparring gym. Mixed martial arts had become the new craze amongst teenagers since medical technology had now made injuries basically nonexistent. I trained 6 days a week and ate clean. Training was my life. Not many of my friends took our new hobby as seriously as I did. Except Cameron. \n",
      " \n",
      " I was the last of my friends to turn, which meant I was the last to gain my power. Some of my friend's powers were utterly useless, like Trevor for example, who was blessed with the power to chug anything as fast as it would pour. Cool party trick, but absolutely useless. When I was born, the doctors noticed the birthmarks on my hands. Little rough patches by my knuckles that almost looked like welds. The doctors had warned my parents that my ability would be powerful. Extremely powerful. \n",
      " \n",
      " The night before my sixteenth birthday happened to coincide with The Tournament. They refused to give it a name other than The Tournament. Martial\n",
      "\n",
      "=== GENERATED STORY 1 ===\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      "\n",
      "A:\n",
      "\n",
      "The power of the sun is the same as the power of the moon.\n",
      "\n",
      "A:\n",
      "\n",
      "The sun is the same as the moon. \n",
      "\n",
      "The sun is the same as the moon. \n",
      "\n",
      "\n",
      "=== GENERATED STORY 2 ===\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      "\n",
      "A:\n",
      "\n",
      "The power of a 16-bit computer is not limited to the 16 bits of the CPU.  The power of a 16-bit computer is not restricted by the CPU.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is not limited by the CPU.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 16-bit computer is limited by the CPU, but it can be increased by a few bits.  The power of a 1\n"
     ]
    }
   ],
   "source": [
    "prompt=valid_text[200][:valid_text[200].find('<sep>')]\n",
    "target=valid_text[200][valid_text[200].find('<sep>')+5:]\n",
    "\n",
    "input_ids = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "def generate_story(prompt,target,model):\n",
    "    print(\"====PROMPT====\\n\")\n",
    "    print(prompt+\"\\n\")\n",
    "    print('====CORRESPONDING STORY===\\n')\n",
    "    print(target+\"\\n\")\n",
    "    input_ids = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    \n",
    "   \n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        max_length=300,\n",
    "        temperature=0.9,\n",
    "        top_k=2,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for generated_sequence_idx, generated_sequence in enumerate(gen_tokens):\n",
    "        print(\"=== GENERATED STORY {} ===\".format(generated_sequence_idx + 1))\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "        # Decode text\n",
    "        gen_text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "        # Remove all text after eos token\n",
    "        gen_text = gen_text[: gen_text.find(tokenizer.eos_token)]\n",
    "        print(gen_text)\n",
    "\n",
    "generate_story(prompt,target,model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0b3ac-7623-4d93-a4ac-f1ba3055345d",
   "metadata": {},
   "source": [
    "Sada ćemo koristiti model koji je fino podešen kako bismo generirali priče s istim promptom koji je korišten prije finog podešavanja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f056dc0a-9605-4d89-8d81-1b3f2a49f0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T13:53:13.373714Z",
     "iopub.status.busy": "2023-08-29T13:53:13.373042Z",
     "iopub.status.idle": "2023-08-29T13:53:35.618120Z",
     "shell.execute_reply": "2023-08-29T13:53:35.617190Z",
     "shell.execute_reply.started": "2023-08-29T13:53:13.373686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====PROMPT====\n",
      "\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      "\n",
      "====CORRESPONDING STORY===\n",
      "\n",
      " The funeral was the saddest day of my life. I watched as Cameron's mother and father wept over a closed casket. No parent should ever have to bury their child. That is an agony I wouldn't wish on my worst enemy. They tried their best to avoid giving me terrible looks between the tears, but who could blame them? I had just killed their son. \n",
      " \n",
      " Days in the summer had become pretty routine. Wake up, eat breakfast, long run, jump in the pool, and then the fun part, go with a few friends to the sparring gym. Mixed martial arts had become the new craze amongst teenagers since medical technology had now made injuries basically nonexistent. I trained 6 days a week and ate clean. Training was my life. Not many of my friends took our new hobby as seriously as I did. Except Cameron. \n",
      " \n",
      " I was the last of my friends to turn, which meant I was the last to gain my power. Some of my friend's powers were utterly useless, like Trevor for example, who was blessed with the power to chug anything as fast as it would pour. Cool party trick, but absolutely useless. When I was born, the doctors noticed the birthmarks on my hands. Little rough patches by my knuckles that almost looked like welds. The doctors had warned my parents that my ability would be powerful. Extremely powerful. \n",
      " \n",
      " The night before my sixteenth birthday happened to coincide with The Tournament. They refused to give it a name other than The Tournament. Martial\n",
      "\n",
      "=== GENERATED STORY 1 ===\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      " <sep> I was born with a power. It was a strange one, I don't know what it was or why it happened, but it was something that I had never really thought about before. The first time it happened, it was a little scary. My parents had been worried about me growing up with a power like this, but they had no idea how to handle it. They had to keep it hidden from everyone else. But I knew that I could be a hero. And so, I did what any good parent would do: I became a superhero. \n",
      " \n",
      " When my parents were diagnosed with cancer, they had to go through a lot of chemo. At first, they tried everything. A lot of them tried drugs. Some of them tried to stop me from killing myself. Others tried to make me stronger. But I was always stronger than them. So, I was given a power that I never thought I could use, and it made me stronger than anyone else. \n",
      " \n",
      " After my parents passed away, I started to grow up. People started calling me the Hero. I was the only one who knew that I could d\n",
      "=== GENERATED STORY 2 ===\n",
      "[ WP ] Every person in the world develops a weird mutation/power the day they turn 16. Everyone's powers are always different, some more insignificant than others. You turn 16, and watch as all your friends discover their newfound ability's. That is, until you discover the severity of your own. \n",
      " <sep> `` I'm not sure what to do about it '' I thought. The last time we met was the day before my 16th birthday. We were walking down the street, and I was looking at a man who looked like he was about to die. He was wearing a suit, and a black tie. His face was covered by a black hood, and his eyes were red. \n",
      " \n",
      " `` Hey, buddy! How's it hanging? '' I asked. He looked up at me, and I could see that his face was a mix of anger and sadness. \n",
      " \n",
      " `` It's fine. Just a little bit worried. What's wrong with you? '' He asked. I didn't answer him. \n",
      " \n",
      " `` Well, I don't know. My power isn't working anymore, but it's still working. '' I said. \n",
      " \n",
      " `` Oh... '' He said, and I could feel the tears starting to form in his eyes. \n",
      " \n",
      " `` Yeah, well, I guess I'll just have to try it sometime. Maybe tomorrow? '' I asked. \n",
      " \n",
      " `` Sur\n"
     ]
    }
   ],
   "source": [
    "generate_story(prompt,target,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5486b-7fdd-4fc9-a12c-e501f9a0be46",
   "metadata": {},
   "source": [
    "## 6.Evaluacija nakon finog podešavanja modela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b5dfc-eb07-4d29-95c6-b17b2b4eeca5",
   "metadata": {},
   "source": [
    "Nakon finog podešavanja, možemo vidjeti da je perpleksnost za validacijski skup podataka otprilike 23, što je znatno bolji rezultat nego prije finog podešavanja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3f0bb3d-4b9a-4965-8c92-12f24f94243b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T14:00:12.060639Z",
     "iopub.status.busy": "2023-08-04T14:00:12.060096Z",
     "iopub.status.idle": "2023-08-04T14:00:12.463704Z",
     "shell.execute_reply": "2023-08-04T14:00:12.462997Z",
     "shell.execute_reply.started": "2023-08-04T14:00:12.060617Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=traindata,\n",
    "    eval_dataset=validdata,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03ef7105-67ad-4a98-add0-a7256f42abd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T14:00:21.232845Z",
     "iopub.status.busy": "2023-08-04T14:00:21.232420Z",
     "iopub.status.idle": "2023-08-04T14:07:07.910122Z",
     "shell.execute_reply": "2023-08-04T14:07:07.909569Z",
     "shell.execute_reply.started": "2023-08-04T14:00:21.232823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 06:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b89ccfb-f14b-4f6a-a28a-63286f32ea0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T14:07:28.896719Z",
     "iopub.status.busy": "2023-08-04T14:07:28.895925Z",
     "iopub.status.idle": "2023-08-04T14:07:28.902708Z",
     "shell.execute_reply": "2023-08-04T14:07:28.901837Z",
     "shell.execute_reply.started": "2023-08-04T14:07:28.896683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average perplexity for valid dataset after fine-tuning is:  23.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average perplexity for valid dataset after fine-tuning is:  {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33c1df-3c04-4eb1-9bb6-573f4d51ce23",
   "metadata": {},
   "source": [
    "## 7.Zaključak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e11661-9216-4bb4-a1d8-d02da6d54620",
   "metadata": {},
   "source": [
    "Kako sam započeo ovaj projekt, preuzeo sam uzbudljiv izazov finog podešavanja GPT-Neo modela koristeći posebno odabrani skup podataka ispunjen zanimljivim pričama iz fikcije. Rezultati su bili zanimljivi, jer su pokazali jasno poboljšanje perpleksnosti, što znači da je razumijevanje teksta modela značajno napredovalo. Još zanimljivije je da, kada sam procijenio priče generirane fino podešenim modelom, primijetio da je i kvaliteta znatno porasla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc835a22-a60d-499c-bf6e-341b07ce4540",
   "metadata": {},
   "source": [
    "Međutim, kao student, teško je ne uvidjeti da generativno modeliranje jezika predstavlja izuzetno kompleksan posao. Rastuća razlika između ljudske kreativnosti i sposobnosti umjetne inteligencije postaje sve očitija. Naša vještina oblikovanja priča, prenošenje emocija i prilagođavanje različitim stilovima pisanja dokaz su kompleksnosti ljudskog jezika."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87f170-2658-41cd-b47f-6aa896d1a695",
   "metadata": {},
   "source": [
    "Iako postižemo impresivan napredak, moramo shvatiti da smo i dalje daleko od kopiranja dubine i bogatstva ljudskog jezika.\n",
    "\n",
    "**GPT-Neo** je koristan alat, ali nije čarobnjak kada je riječ o pisanju cjelovitih priča od 300 riječi. Može biti koristan za prevladavanje blokade pisanja i poticanje kreativnosti, ali nedostaje mu potpuna automatizacija generiranja fikcijskih priča.\n",
    "\n",
    "Međutim, nemojte očekivati da će GPT-Neo obaviti sve teške zadatke. Nije sposoban stvoriti potpunu priču od početka do kraja s dubinom i emocijama koje može pružiti ljudski pisac.\n",
    "\n",
    "Umjesto toga, koristite **GPT-Neo** kao pomoćnika u pisanju.\n",
    "To je koristan alat za pisce, ali nije zamjena za ljudsku maštovitost i vještine pripovijedanja.\n",
    "Dakle, iako može biti koristan dio vašeg procesa pisanja, nije prečac do potpunog automatiziranog pisanja fikcije."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a936da2-3515-4cf8-9b9f-b5bdd894dff4",
   "metadata": {},
   "source": [
    "Također sam pokušao stvoriti nove priče koristeći trenutačne promptove s iste Reddit stranice [ WritingPrompts forum](https://www.reddit.com/r/WritingPrompts/), a ovo su rezultati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27df659-1b54-4f12-a7f3-3fe22bfb9e04",
   "metadata": {},
   "source": [
    "---\n",
    " ***Example Prompt 1*** : You traveled a year into the future and saw the Earth devoid of life. You wanted to find out what happened and went back day by day, over a 1000 days and there are still no signs of life.\n",
    "```\n",
    "\n",
    "\n",
    "`` What is this? '' \n",
    " \n",
    " I looked up from my book. It was a book I had been reading for years now. A book that had been my home for the past 3 years. My father had always told me that it was a book he had read when he was a child, but I never understood. The pages were black and the words were black. \n",
    " \n",
    " `` This is the future. We have been here for 1000 days and nothing has changed. There is no sign of life in the world. But we have to go forward. If we don't we will be destroyed. So we must go forward. '' \n",
    " \n",
    " I stood there for a few seconds, confused as to why I was still here. I looked around. Everything was black. No sign of life. Nothing. Just a blank white room with nothing. \n",
    " \n",
    " Then I saw it. A small, black object. It was a large, black box. I could not tell where the box ended or what it was made of. I looked closer. It was a large, black cube. I looked again. It was made of metal, and it was covered in dust.\n",
    " ```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0443ef-6afe-4c07-a1a7-e7fc032dd3a0",
   "metadata": {},
   "source": [
    "---\n",
    " ***Example Prompt 2*** : 'Need a hand?', you nod, and watch in horror as your friend lends you a still-warm, still-twitching, perfectly amputated hand from their pocket.\n",
    "```\n",
    "\n",
    "I'm not sure if this is what I wanted to write, or if it's the only thing I've been able to get out of my life for. \n",
    " \n",
    " It was a normal day at work when I received an email that said `` Need help with your new prosthetic? '' I looked up from the computer screen to see my boss, Mr. Smith, sitting on his couch, reading a book about prosthetics and how they could be used to replace people who have lost their limbs. He had a clipboard with him and a pen, and he was scribbling away. \n",
    " \n",
    " `` What do you mean, 'need a hand '? '' I asked, trying to sound as inconspicuous as possible. \n",
    " \n",
    " `` Well, we're all about prosthetics right now. We can't use them to replace people who have lost their limbs, because there's no other way around it. So we need to make sure we don't lose our hands. And we need to keep them warm so they can't die. That's why we're going to make sure that they stay warm, and that they're still alive. You'll have to find a replacement. '' \n",
    " \n",
    " The man on the couch looked at me\n",
    " \n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1ade5-3de6-478f-a753-ecc9474b0892",
   "metadata": {},
   "source": [
    "---\n",
    " ***Example Prompt 3*** : You are cooking lunch in the kitchen when you suddenly realize that you have misplaced your kitchen knife. Luckily, when you turn around, your teddy bear is holding a knife and approaching you.\n",
    "```\n",
    "\n",
    " `` I'm sorry, but I don't think this is what I wanted. '' \n",
    " \n",
    " The knife was still in his hand, but it had already begun to move. It had been a long day at work, and he was tired of working for himself. He was tired of the boss, and the constant reminders that he was a failure. His boss had been the same as always, but he was different. He was different from everyone else, and he had to make sure that everyone was right. But he was not. \n",
    " \n",
    " He had to make sure that he was right. And so, he began to make his way towards the kitchen. He had to make sure that the teddy bear was holding the knife. That was the first thing he had to do. \n",
    " \n",
    " As he approached, he noticed something that he had never seen before. A small, round object. It was a small, wooden box. It was made out of a plastic, and it had been placed on the floor. There was a large hole on the bottom of the box, and it was covered in a thick layer of dirt. \n",
    " \n",
    " He looked around, and found that he was in a large, wooden room with a larg\n",
    " \n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c692-a643-464b-ab46-b020f03a3353",
   "metadata": {},
   "source": [
    "---\n",
    " ***Example Prompt 4*** : After being eaten by a monstrous whale, you sing to pass the time; unknowingly, your voice becomes a Siren, drawing in doomed sailors.\n",
    "```\n",
    "\n",
    " `` I'm sorry, '' I said. \n",
    " \n",
    " She looked up at me, her eyes wide and her face pale. \n",
    " \n",
    " `` It's okay. We're not gon na be able to get back to the ship again, '' she said, her voice cracking. \n",
    " \n",
    " I looked down at my feet, and I saw the ocean. The waves crashed against the rocks, crashing into the shoreline. A few of the sailors were still alive, and I could hear the screams of the sailors. They were screaming for help. \n",
    " \n",
    " `` What are you doing? '' she asked. Her voice was soft and soothing. \n",
    " \n",
    " `` Just singing. You can't hear us. '' \n",
    " \n",
    " I looked at her, and I saw the sea. It was a sea that was not mine. It was a sea of fire and pain. \n",
    " \n",
    " `` Why did you do this to us? Do we have to die? '' \n",
    " \n",
    " `` No, no, it doesn't matter. This is the only thing that matters. '' \n",
    " \n",
    " I looked at the ocean again, and I saw the ocean. The waves crashed against the rocks, crashing into the shoreline. A few of the sailors were still aliv\n",
    " \n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
